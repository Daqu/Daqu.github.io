[{"content":"\n\n# 完成的工作~\n\n1.简单的了解一下swift middleware机制\n\n看了这篇文章[《对象存储：OpenStack Swift应用、管理与开发》 第八章 部署Swift中间件](http://www.sohu.com/a/163874929_314773)\n\n2.尝试写了一个wsgi的hello world应用。因为middleware的本质是wsgi","cover":"","link":"misc/2017/09/05/daqu-9-5.html","preview":"\u003cp\u003e只是看了下接下来要研究的swift middleware\u0026hellip;\u003c/p\u003e\n","title":"17-09-05 日报"},{"content":"\n\n# 完成的任务~\n\n1.SDS原型（三)缓慢推进，今天的进展主要是:\n\n- 理清了管道化、分层、插件化三者的关系，它们其实是按照分层，插件，管道的顺序有循序渐进的关系。管道化是最终的形态\n- 在文章对上述作了解释\n- 思考如何将weedfs管道化，今天的收获是，每个模块都应该提供相似的调用api，这么做的目的是让它们在架构上有相似性。在调用的时候能比较方便。文章中只是记录这个想法，但还没有解释。\n\n2.正在观察weedfs的老版本，希望找到一个不错的版本用于修改。目标是：\n\n- 基本功能完备，这里重点是bug少\n- 架构清晰","cover":"","link":"misc/2017/08/30/daqu-8-30.html","preview":"\u003cp\u003e将SDS原型(三)推进了一部分\u0026hellip;\u003c/p\u003e\n","title":"17-08-30 日报"},{"content":"\n\n完成的工作~\n\n1.写了两篇输出","cover":"","link":"misc/2017/08/29/daqu-8-29.html","preview":"\u003cp\u003e效率不高\u0026hellip;\u003c/p\u003e\n","title":"17-08-29 日报"},{"content":"\n\n# 将seaweedfs变成SDS的思路\n\nseaweedfs变成SDS的思路总结一下就是\n\n1. 先调整而不是重构，不修改功能\n2. 先调整架构，再调整模块\n\n## 1.分层\n\n将各功能模块按照[MVC](https://baike.baidu.com/item/MVC%E6%A1%86%E6%9E%B6/9241230?fr=aladdin\u0026fromid=85990\u0026fromtitle=MVC)的设计理念分为控制、数据层\n\n**问题**：seaweedfs中的网络部分倾向于控制，文件部分倾向于数据。但是按照这种思路处理无法解决在SDS原型(二)中提到的问题，就是网络请求转为文件请求后，从文件请求开始到文件响应发出这部分无法做控制。原因是按照MVC的思想，文件部分已经是数据层了，从网络应用的角度来说这是对的，但是从存储系统来说这是不对的，因为在底层的文件读取函数被调用前发生的过程都可以算入控制。\n\n总结一下，MVC思想分层的问题在于控制层太小，数据层太大。\n\n## 2.管道化\n\n将seaweedfs的一次请求-响应的过程看成是请求流入管道，并最终流出管道成为响应的过程。SDS的控制体现在数据在经过管道时会发生变化，管子组合在一起形成管道，也就是控制层。\n\n**问题**：管道是个很抽象的概念，如何将seaweedfs中一次请求-响应的过程抽象为一个操作序列是个问题。举个例子，比如seaweedfs的网络部分已经被看成是一个管子，这根管子负责网络请求的收发和转化。为了更细腻的控制，可以将这根管子拆成更多的管子。为了更清晰的架构，可以将这根管子和其它管子组合成更大的管子。问题就是，如何描述这种机制，用管子组成管道的机制。\n\n总结一下，管道化难以抽象。\n\n## 3.插件化\n\n将seaweedfs看成是一块插满插头的插座。将各功能模块看成是插头，将要实现的控制层看成是插座。插座加插头形成seaweedfs。他的特点在于各功能模块之间的耦合度很低。\n\n**问题**：根据插件化的介绍，数据层变得模糊，或者是数据层重要性不如控制层重要，因为它只是个插头，虽然没了这个插头不行。但从架构上说好像不大好。\n\n总结一下，先不提实现难度，优点和缺点都不突出。","cover":"","link":"misc/2017/08/29/将seaweedfs变成sds的思路.html","preview":"\u003cp\u003eseaweedfs变成SDS的思路\u0026hellip;\u003c/p\u003e\n","title":"将seaweedfs变成SDS的思路"},{"content":"\n\n# 使用elixir来开发一个分布式存储系统\n\nerlang作为一门老语言，在分布式架构越来越流行的今天，它正在重焕光彩。在分布式系统中各节点如何通信以及共享状态其实是一个问题，比如openstack swift的各存储节点之间为了保证存储状态的一致，除了通过一致性算法制定策略外，还需要强有力的通信机制来保证通信质量。erlang在这方面有架构上的优势，而它的OTP则为编写高性能、高容错的分布式应用提供一个框架。elixir是基于erlang vm的语言，它封装了许多erlang的操作，它可以与erlang无缝配合，它可以说是更好的erlang。leofs、亚马逊的riak都是用erlang构建的存储系统。下面，笔者将简单介绍如何使用elixir开发一个分布式存储系统，这是对elixir 的一个教学例子的总结。\n\n## OTP是什么\n\nOTP是一套应用框架，它阐述了如何在erlang 虚拟机上开发一个完整的应用。OTP是Open Telecom Platform的缩写。\n\n\u003e OTP的中心思想就是把程序的通用部分和业务部分切开，我帮你把通用部分做好，你做你的业务逻辑就行了。如果你看过一些分布式系统，最火的应该是分布式存储系统了，像Amazon的Dynamo、Google的Bigtable、LiveJournal的memcache等，就知道保证分布式系统的容错能力、数据一致性、请求高并发性是非常困难的。但是他们所用的算法都非常固定，当你去实现另一个分布式系统时，很可能就是参考他们的算法。然后一些技术功底不够的程序员就想，要是能把这些基础的设施都做好，并且提供插件扩展，那多好啊，这样当我想写个分布式数据库的时候就能跟写普通数据库一样简单了。没错，OTP就是帮你干那些又脏又累的活。\n\n## 在Elixir中使用otp\n\nelixir中要使用otp主要用到以下几种抽象\n\n- state\n- agent\n- gen_server\n- supervisor\n\n由于erlang是纯函数式编程语言，因此变量都是一次赋值后便不可变的。但在业务场景中，经常要修改结果。因此erlang提供了抽象state，它可以保存一些结果并允许被修改。\n\nagent相当于是对state的进一步封装，并且agent提供了一系列操作state的函数。\n\ngen_server顾名思义，它其实是一个服务器。它可以处理各种agent的请求。不仅如此，gen_server还可以起到客户端的作用。它可以对agent进一步封装。经常出现的情况就是封装了agent的genserver(客户端)与genserver(服务器)交互。\n\nsupervisor用于监督进程。在OTP中，有这样一种哲学，\"忽略错误，重启就好\"。如果一个erlang 进程crash了，那么就让它崩溃就行了，然后再重启就OK。supervisor就是起到监督进程状态，如果进程崩溃，就做出相应的处理。\n\n## 在elixir中使用otp开发分布式存储\n\n既然otp把基础设施都搭好了，那么使用otp开发一个应用的思路是啥。\n\n1. 编写各功能模块\n2. 通过Agent来保存state，state就是各种结果\n3. 通过Genserver来实现通信\n4. 通过supervisor来保证程序正常运行\n\n由于OTP是一套框架，因此对于分布式和非分布式应用。开发的思路是一样的，也就是说上述的思路不仅可以开发非分布式应用，还可以开发分布式应用。并且架构不用发生太多改变。\n\n## otp的特点\n\n使用otp来开发程序和一般的程序开发流程有较大不同，主要体现在结果的处理和错误的处理。\n\n### 结果的处理\n\notp，或者说erlang更准确一点。其实是没有变量这个概念的，因为变量都是赋值之后不可变的，换句话说就是常量了。对于函数的返回结果，erlang的描述是message，也就是消息。在笔者看来，erlang把每一个erlang 进程都看成是一个邮递员，函数的调用则意味着告诉邮递员，也就是调用这个函数的进程应该如何和别的邮递员通信。每一个邮递员都有一个mailbox(邮箱)，邮箱中会储存其它邮递员发给这个邮递员的消息，但mailbox的中的信息不是长久的，收到下一封信的时候信箱中的消息就被扔掉了。所以需要state这样的机制来保存结果。\n\n在otp中，一个应用的运行事实上是多个erlang 进程相互通信的过程，直白一点就是一群邮递员相互传递信件的过程。这简直就是天然的分布式架构。\n\n### 错误的处理\n\notp中对待错误的观点是不管它，我只要能保证崩溃后还能重启就行了。因此它不会像其它的语言那样try catch final，而是用一个或多个进程去监督一个或多个进程，一旦它们崩溃，就按照设定的步骤重启它。\n\n## 最后\n\n如果感兴趣，可以看看[官方的例子](https://elixir-lang.org/getting-started/mix-otp/introduction-to-mix.html)","cover":"","link":"misc/2017/08/29/使用elixir来开发一个分布式存储系统.html","preview":"\u003cp\u003e简单地介绍了OTP\u0026hellip;\u003c/p\u003e\n","title":"使用elixir来开发一个分布式存储系统"},{"content":"\n\n\n# 完成的工作\n\n1. 对OTP中supervisor有了进一步的了解\n2. 写了一点代码\n\n## 未完成的工作\n\n1. 关于otp输出，但在输出的过程中发现很多不足，作罢","cover":"","link":"misc/2017/08/28/daqu-8-28.html","preview":"\u003cp\u003e效率不高\u0026hellip;\u003c/p\u003e\n","title":"17-08-28 日报"},{"content":"\n\n# 完成的工作~\n\n1.对OTP中Agent、Genserver有了进一步的了解\n\n2.对自己的项目花了两个小时找到一个bug","cover":"","link":"misc/2017/08/28/daqu-8-27.html","preview":"\u003cp\u003e仔细研究OTP\u0026hellip;\u003c/p\u003e\n","title":"17-08-27 日报"},{"content":"\n\n# 完成的工作~\n\n1.构建一个静态博客用来存储日报和输出\n\n2.完成mix和otp分布式存储第三到第五部分。对OTP中的agent，genserver，supervisor以及ETS有了初步的了解","cover":"","link":"misc/2017/08/26/daqu-8-26.html","preview":"\u003cp\u003e搭了一个静态博客，学习OTP中的知识\u0026hellip;\u003c/p\u003e\n","title":"17-08-26 日报"},{"content":"\n\n# SDS原型(一)\n\n什么是软件定义存储？目前有两种实践，基于基础设施的SDS和基于管理的SDS。个人目前倾向于后者\n\n## 什么是基于基础设施的SDS\n\n基于基础设施的SDS指的是，用软件定义的观念就IAAS（基础设施即服务）进行实践。举个例子，很久以前，小王所在的团队负责该公司的运维工作。由于业务需要，小王经常需要给技术人员配置服务器资源。\n\n一开始，小王基本都是手动配置。但是随着任务的增多，小王负责的任务也越来越多。这时他感觉承受不了，因此他要思考怎么样才能应付这种变化。通过仔细分析他发现，每一次配置都在相同的工作，将空闲的服务器IP找出来，检查这个服务器的性能是否满足要求，将密钥和ip发给申请人。每次都做相同的步骤实在是太烦了，因此小王做了一个网站。他每次只需要在网站上点击查找，网站后台便会自动查找一个空闲的服务器，并自动将密钥和ip发给申请者。小王花了一个星期做完这个网站后，果然极大地解放了他。\n\n随着公司的发展，技术人员越来越多，申请服务器资源的人也越来越多。服务器不够用啦！小王向领导申请购置新的服务器，领导说没这么多钱，但还是批了一笔预算，说：公司就只能给这么多啦。小王拿着钱发愁，心想：这点钱怎么够啊？连一台服务器都买不了。正在小王发愁的时候，vmware的销售人员找到他说：老哥，你不是说服务器不够用嘛？小弟这里有一个虚拟机软件，可以在一台机子上模拟好多台机子。不仅如此，公司专门为服务器定制了更好的产品。老哥试试不，要是觉得好，给你打个八折！小王一试，喜出望外。心想：是啊，公司的服务器性能不错，给一个人或许有点浪费，领导给的钱虽然买不起服务器，但是买这个软件还是可以的。在购买了软件之后，小王解决让更多人使用服务器的问题，领导对他表示了赞赏。\n\n几年之后，公司的产品复杂度和规模越来越大。公司的服务器已经不能支撑如此高的负荷。因此小王的团队将公司的机房升级成数据中心，并且升级了虚拟机管理软件，让其支持分布式架构。这样，无论产品的规模有多大，运维这边只需要增加服务器和机房就可以啦。但是渐渐地，通过分析小王发现。产品规模增大对服务器只有存储扩容的需求。也就是说每次扩容增加的CPU、内存等其实都是没必要的。小王就发愁了，这时候他忽然发现了ceph和hdfs。小王一拍大腿，原来存储也可以独立出来搞分布式啊！很快，小王团队就完成了技术升级。将服务器的文件系统换成了分布式文件系统。这样，以后扩容的时候就能减少成本了。\n\n又过了一段时间，领导觉得公司应该拓展一下业务。因此找到小王，说：小王啊，你把公司的服务器管得很好嘛。公司现在需要寻找新的利润点，我看存储就很有搞头嘛！这样吧，交给你个任务，公司打算将服务器上的一些存储资源卖出去，做个云盘、云存储什么的。你来搞个方案把。小王觉得这是个机会，便很撸起袖子打算大干一把。但是通过调研发现，潜在用户对存储的需求各不相同。小张要容量大而便宜的，小明要读取速度快而便宜的，小赵由于在国外，要求访问有保证而便宜的。似乎用户的要求除了便宜之外都各不相同。小王又发现文件系统似乎不能满足所有用户的需求。经过讨论，小王团队决定自己开发一套存储管理系统，针对可能用户做业务定制。\n\n开发过程中的某一天，小王接触到了SDS。他心想：我在做的不就是SDS么，我用软件来管理存储。通过软件，存储资源可以动态分配，硬盘坏了可以自动报警。如果只是一块挂载到文件系统上的硬盘可实现不了这些功能呢。\n\n## 基于管理的SDS\n\n基于管理的SDS可以类比sdn，它的本质是一种架构，是一种思想。它的核心观点是控制和数据分离。从这种观点出发，有些研究者就提出。SDS应该也要践行这种观点，实现控制和数据的分离。\n\n### 控制\n\n在网络中，控制主要聚焦在请求发给谁、谁来执行这两个问题。那么，在存储中有没有类似的问题呢？个人认为有，但不是都有。\n\n目前，存储根据接口的不同可以简单的分为块存储、对象存储、文件存储。日常接触最多的是文件存储，也就是文件系统。\n\n对于文件系统来说，它开发的是posix接口，也就是write、read、list之类的函数调用接口。注意，文件系统开放的接口是函数接口。也就是说一个io请求在这种情况下生命流程并不涉及到控制，因为它只是一个调用的过程。如果要在文件系统级别上实现控制和数据分离，意味着控制层的分离或者说是搭建需要巨大的耗费。那么，在文件系统上实现SDS会不会是本末倒置，这是值得商榷的。\n\n对于块存储来说，作为三者中最底层的存储。它开放的接口一般都是以内核模块或者是驱动存在的，而且它的目的在于将存储挂载。可以将文件存储理解为对块存储的进一步封装。一句话，块存储的定位让我觉得不适合在块存储这个级别实现SDS。\n\n那对象存储呢？一般放在最后的就是答案。在我看来，对象存储开放的接口比较粗暴地说可以理解为就是restful的http接口。在sdn中，控制指的是请求转发的控制。但在存储中，在一次操作中三种存储能够理解成请求的只有对象存储，其它两种存储我觉得用调用来描述更加准确。也就是说，在我看来。控制和数据分离中控制是有前提的，也就是控制这个动作的主体得是和sdn中提到的请求有类似功能的个体才可以。因此，我认为对象存储在实现SDS中有独特的优势。举个例子，openstack swift存在一个中间件机制，通过中间件swift可以对上传的文件进行校验验证、名称合法性验证等操作。\n\n### 数据\n\n当控制和数据分离的时候，数据其实是不能按照原来的方式进行处理的。在我看来，控制和数据分离其实不仅要求控制层的独立，还对数据层有要求，也就是要进行抽象。前面提到，在网络中，控制主要聚焦在请求发给谁、谁来执行这两个问题。就这个观点来说，数据层其实就是要解决请求发给谁和谁来执行中的谁是什么的问题。就文件存储和块存储来说，这其实是一个没有必要的操作。举个例子，文件系统如果对数据进行封装，那它和对象存储有什么区别？\n\n那么对于对象存储来说应该怎么解决呢？在我看来，对象存储中的存储原子也就是对象(object)已经是完备的数据层，因为它已经实现了对存储的抽象。举个例子，haystack中的小文件在存储里面都被抽象成一个needle。\n\n### 结论\n\n由于对象存储的架构与SDS控制和数据分离观点的匹配，我认为凡是实现了restful接口的对象存储系统都可以看成是SDS的存储系统。\n\n## 对象存储VS文件系统\n\n对象存储和文件系统的比较其实换一种说可以是软件定义存储相比于传统存储的优势是什么。\n\n\u003e 在早些年，特别是2006年以前，人们提到对象存储，往往指的是以类似标准化组织SNIA定义的OSD（object storage device）和MDS（Metadata Server）为基本组成部分的分布式存储，通常是分布式文件系统。我们经常听到的分布式存储Ceph的底层RADOS（Reliable Autonomous Distributed Object Store），即属于这类对象存储。\n\u003e\n\u003e 而2006年以后，人们说到对象存储，往往指的是以AWS的S3为代表的，通过HTTP接口提供访问的存储服务或者存储系统。类似的系统还有Rackspace于2009年开始研发并于2010年开源的[OpenStack](http://lib.csdn.net/base/openstack) [Swift](http://lib.csdn.net/base/swift)（Rackspace的对象存储服务开始于2008年，但是[swift](http://lib.csdn.net/base/swift)项目的开发是从2009年开始的，Rackspace用Swift项目对其云存储系统进行了彻底重构）。这里的“对象”（Object）和我们平时说的文件类似，如果我们把一个文件传到对象存储系统里面存起来，就叫做一个对象。\n\n从上面可以看到，对象存储的定义随着时间的发展是一直在改变的。从一种架构到代表一种存储形态。现在，对象存储已经是某种存储形态的代名词，而不再是指某种文件系统架构了，相应的文件系统架构也有了专有的名字比如分布式文件系统等等。\n\n就操作粒度来说，文件系统可以比对象存储操作得更加细致。文件系统不局限于文件，通过特定的调用还可以操作块、inode等等。但是对象存储的最小粒度只是对象，最大粒度还是对象。随着计算机的发展，逻辑层次上的方便程度随着业务规模的扩大愈发重要。\n\n\u003e 对象存储和文件系统在接口上的本质区别是对象存储不支持和`fread`和`fwrite`类似的随机位置读写操作，即一个文件PUT到对象存储里以后，如果要读取，只能GET整个文件，如果要修改一个对象，只能重新PUT一个新的到对象存储里，覆盖之前的对象或者形成一个新的版本。\n\u003e\n\u003e 如果结合平时使用云盘的经验，就不难理解这个特点了，用户会上传文件到云盘或者从云盘下载文件。如果要修改一个文件，会把文件下载下来，修改以后重新上传，替换之前的版本。实际上几乎所有的互联网应用，都是用这种存储方式读写数据的，比如[微信](http://lib.csdn.net/base/wechat)，在朋友圈里发照片是上传图像、收取别人发的照片是下载图像，也可以从朋友圈中删除以前发送的内容；微博也是如此，通过微博API我们可以了解到，微博客户端的每一张图片都是通过REST风格的HTTP请求从服务端获取的，而我们要发微博的话，也是通过HTTP请求将数据包括图片传上去的。在没有对象存储以前，开发者需要自己为客户端提供HTTP的数据读写接口，并通过程序代码转换为对文件系统的读写操作。\n\n此外，对象存储拥有扁平化的数据结构。这个特点让它不用维护目录树，这在处理海量文件的时候会优势。对象存储K/V的存储的方式也能保证查找效率。\n\n先这样吧。","cover":"","link":"misc/2017/08/26/sds原型(一).html","preview":"\u003cp\u003esds目前的情况\u0026hellip;\u003c/p\u003e\n","title":"SDS原型（一）"},{"content":"\n## seaweedfs简单介绍\n\nseaweedfs是haystack的一个开源实现。名字是海草，这也反映了它和haystack(草垛的关系)\n\n#### 架构\n\n\u003e 分布式文件系统的拓扑结构大体都类似，分为NameNode和DataNode，NameNode负责管理数据节点拓扑结构以及元数据，DataNode负责真实数据存储；在seaweedfs文件系统中，NameNode称为Master，DataNode称为VolumeServer。\n\u003e\n\u003e ![架构](http://7xjnip.com1.z0.glb.clouddn.com/ldw-IMG_07861.JPG)\n\u003e\n\u003e 由架构图可以看出，\n\u003e\n\u003e - Master负责管理集群的拓扑结构，分为主从结构，并采用raft实现主从复制和高可用，以此消除单点问题；TFS中的NameNode为了消除单点问题，采取的是虚拟IP配上lvs；\n\u003e - DataNode负责存储具体数据，并与M-Master保持心跳，上报自己的存储信息；\n\u003e\n\u003e 当客户端需要存储数据时，\n\u003e\n\u003e 1. 需要先给M-Master发送请求，获取该文件存储的DataNode地址，文件存储的VolumeID以及文件fid;\n\u003e 2. 然后客户端接着将文件发送至从Master获取到的DataNode，DataNode会根据VolumeID找到相应的Volume，并将文件存储到该Volume;\n\u003e\n\u003e \u003e 分布式文件系统数据节点存储数据时，会创建出若干个大文件(可以想象为磁盘)，用于存储小文件，例如文件，短视频等等；在seaweedfs中，大文件就称为Volume；\n\u003e\n\u003e ok，上述是正常情况下seaweedfs运行时的整体架构图，但是机器的东西，说不准哪天就挂了，特别是Master，因为Master挂了，整个文件系统就不可用了；在seaweedfs是通过raft实现高可用，即使M-Master挂了，会通过选举算法，在S-Master选举出新的M-Master，然后所有DataNode则将自己的信息上报给新的M-Master；结构图如下:\n\u003e\n\u003e ![容错](http://7xjnip.com1.z0.glb.clouddn.com/ldw-IMG_07871.JPG)\n\u003e\n\u003e 图中可以看出，当M-Master挂了之后，剩余两个S-Master会进行选举，产生新的M-Master，此时所有的DataNode将会连接到新的M-Master，并上报自己的存储信息；而客户端下次需要存储文件时，会先到选举产生的新M-Master获取DataNode信息，然后再将文件存储到具体DataNode；\n\u003e\n\u003e 这里，client是如何连接到新的M-Master的，我不是很清楚，因此没有在实际生产环境中部署使用过，但是我觉得可以通过客户端轮询来实现。\n\u003e\n\u003e 接下来，我们来看下Master拓扑结构，如下图:\n\u003e\n\u003e ![topology_arch](http://7xjnip.com1.z0.glb.clouddn.com/ldw-IMG_07881.JPG)\n\u003e\n\u003e seaweedfs拓扑结构主要有三个概念，数据中心(DataCenter)，机架(Rack)，数据节点(DataNode)；这样可以很灵活配置不同数据中心，同一个数据中心下不同机架，同一机架下不同的数据节点；数据都是存储在DataNode中；\n\u003e\n\u003e 最后再来看下DataNode存储节点Volumn布局；如下:\n\u003e\n\u003e ```shell\n\u003e +-------------+\n\u003e | SuperBlock  |\n\u003e +-------------+\n\u003e | Needle1     |\n\u003e +-------------+\n\u003e | Needle2     |\n\u003e +-------------+\n\u003e | Needle3     |\n\u003e +-------------+\n\u003e | Needle...   |\n\u003e +-------------+\n\u003e ```\n\u003e\n\u003e 一般情况下，一个DataNode会配置多个Volume，这样可以避免多个客户端对同一个Volume读写争抢；每个Volume由一个SuperBlock和若干个Needle组成；每个Needle则代表一个小文件，例如图片和短视频\n\n#### 安装与使用\n\nseaweedfs的安装很简单，它本身编译后就只有一个可执行文件，也不依赖额外的库。但是我是在windows在进行安装，因此还需要额外安装[curl](https://curl.haxx.se/)。curl本身也是编译好的程序，将它的`bin`目录加进环境变量。为了省事，我把`weedfs.exe`扔进了curl的`bin`目录，这样安装过程就完成了。\n\nseaweedfs的启动很简单，他需要至少一个master服务和一个storage服务。在这里，master和storage服务都在一台机子上。组合是一个master和两个storage。启动过程如下：\n\nMASTER\n\n```powershell\n# in windows 10 x64\nC:\\Users\\aloor\u003ecd Desktop\nC:\\Users\\aloor\\Desktop\u003ecd temp\nC:\\Users\\aloor\\Desktop\\temp\u003eweed master\n\nI0808 15:46:57 13248 file_util.go:20] Folder C:\\Users\\aloor\\AppData\\Local\\Temp Permission: -rwxrwxrwx\nI0808 15:46:57 13248 master_server.go:62] Volume Size Limit is 30000 MB\nI0808 15:46:57 13248 master.go:87] Start Seaweed Master 0.76 at 0.0.0.0:9333\nI0808 15:46:57 13248 raft_server.go:56] Peers Change: [localhost:9333] =\u003e []\nI0808 15:46:57 13248 raft_server.go:98] Initializing new cluster\nI0808 15:46:57 13248 master_server.go:95] [ localhost:9333 ] I am the leader!\n```\n\nSTORAGE\n\n```powershell\n# in windows 10 x64\nC:\\Users\\aloor\u003ecd Desktop\nC:\\Users\\aloor\\Desktop\u003ecd temp\nC:\\Users\\aloor\\Desktop\\temp\u003eweed volume -dir=\".\\data1\" -max=5  -mserver=\"localhost:9333\" -port=8080\nI0808 15:49:27  5468 file_util.go:20] Folder .\\data1 Permission: -rwxrwxrwx\nI0808 15:49:27  5468 disk_location.go:106] Store started on dir: .\\data1 with 0 volumes max 5\nI0808 15:49:27  5468 volume.go:143] Start Seaweed volume server 0.76 at 0.0.0.0:8080\nI0808 15:49:27  5468 volume_grpc_client.go:17] Volume server bootstraps with master localhost:9333\nI0808 15:49:27  5468 volume_grpc_client.go:52] Heartbeat to localhost:9333\n```\n\n```powershell\n# in windows 10 x64\nC:\\Users\\aloor\u003ecd Desktop\nC:\\Users\\aloor\\Desktop\u003ecd temp\nC:\\Users\\aloor\\Desktop\\temp\u003eweed volume -dir=\".\\data2\" -max=5  -mserver=\"localhost:9333\" -port=8081\nI0808 15:49:58  9560 file_util.go:20] Folder .\\data2 Permission: -rwxrwxrwx\nI0808 15:49:58  9560 disk_location.go:106] Store started on dir: .\\data2 with 0 volumes max 5\nI0808 15:49:58  9560 volume.go:143] Start Seaweed volume server 0.76 at 0.0.0.0:8081\nI0808 15:49:58  9560 volume_grpc_client.go:17] Volume server bootstraps with master localhost:9333\nI0808 15:49:58  9560 volume_grpc_client.go:52] Heartbeat to localhost:9333\n```\n\n上传文件\n\n```powershell\n# in windows 10 x64\nC:\\Users\\aloor\u003ecd Desktop\nC:\\Users\\aloor\\Desktop\u003ecurl -X POST http://localhost:9333/dir/assign\n{\"fid\":\"1,01de988801\",\"url\":\"127.0.0.1:8081\",\"publicUrl\":\"127.0.0.1:8081\",\"count\":1}\nC:\\Users\\aloor\\Desktop\u003ecurl -X PUT -F file=@.\\crystal.txt http://127.0.0.1:8081/1,01de988801\n{\"name\":\"crystal.txt\",\"size\":1147}\n```\n\n接下来通过`http://127.0.0.1:8081/1,01de988801`就可以在浏览器上看到刚才上传的文件了。\n\n#### 总结\n\nseaweedfs虽然说是file system。但它其实是一个对象存储，这可以和openstack swift类比。\n\n- seaweedfs的master和datanode对应着swift的proxy server和storage node。\n\n- 两者都支持http接口访问。\n\n- seaweedfs没有swift的middleware组件，因此目前无法编写插件。\n\n- seaweedfs的元数据是分层维护的。master维护的是各volume的信息。volume维护自己存储中的小文件的元数据。swift则是将元数据放到对象上。\n\n- seaweedfs的文件元数据是定制过的，有大小限制。每个文件的元数据大约8 bytes。作为对比，一个xfs_inode_t结构在Linux中需占用536 bytes。\n\u003e 当前，Haystack平均为每个图片使用10byte的内存。每个上传的图片对应4张副本，它们共用同一个key（占64bits），alternate keys不同（占32bits），size不同（占16bits），目前占用(64+(32+16)*4)/8=32个bytes。另外，对于每个副本，Haystack在用hash table等结构时需要消耗额外的2个bytes，最终总量为一张图片的4份副本共占用40bytes。\n\n\n\n参考：\n\n1. [SeaweedFS概述](http://luodw.cc/2017/01/05/weedfs/)","cover":"","link":"misc/2017/08/26/seaweedfs简单介绍.html","preview":"\u003cp\u003eseaweedfs简单介绍\u0026hellip;\u003c/p\u003e\n","title":"seaweedfs简单介绍"},{"content":"\n\n# weedfs生命流程\n\n## (入口)./weed.go\n\n总入口，执行过程如下\n\n```go\nfunc main() {\n\tglog.MaxSize = 1024 * 1024 * 32 \n\trand.Seed(time.Now().UnixNano())\n\tflag.Usage = usage\n\tflag.Parse()\t//设置一下背景\n\n\targs := flag.Args()\n\tif len(args) \u003c 1 {\n\t\tusage()\n\t}\n//如果第一个参数是help，则跳转到help\n\tif args[0] == \"help\" {\n\t\thelp(args[1:])\n\t\tfor _, cmd := range commands {\n\t\t\tif len(args) \u003e= 2 \u0026\u0026 cmd.Name() == args[1] \u0026\u0026 cmd.Run != nil {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"Default Parameters:\\n\")\n\t\t\t\tcmd.Flag.PrintDefaults()\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\t\n//主入口，根据commands构造参数，并执行run方法\n\tfor _, cmd := range commands {\n\t\tif cmd.Name() == args[0] \u0026\u0026 cmd.Run != nil {\n\t\t\tcmd.Flag.Usage = func() { cmd.Usage() }\n\t\t\tcmd.Flag.Parse(args[1:])\n\t\t\targs = cmd.Flag.Args()\n\t\t\tIsDebug = cmd.IsDebug\n\t\t\tif !cmd.Run(cmd, args) {\n\t\t\t\tfmt.Fprintf(os.Stderr, \"\\n\")\n\t\t\t\tcmd.Flag.Usage()\n\t\t\t\tfmt.Fprintf(os.Stderr, \"Default Parameters:\\n\")\n\t\t\t\tcmd.Flag.PrintDefaults()\n\t\t\t}\n\t\t\texit()\n\t\t\treturn\n\t\t}\n\t}\n//有错误就输出\n\tfmt.Fprintf(os.Stderr, \"weed: unknown subcommand %q\\nRun 'weed help' for usage.\\n\", args[0])\n\tsetExitStatus(2)\n\texit()\n}\n```\n\n其中cmd.run函数的签名如下，接受一个命令和参数\n\n```go\nRun func(cmd *Command, args []string) bool\n```\n\nCommand的结构如下\n\n```go\nvar Commands = []*Command{\n\tcmdBenchmark,\t//测试\n\tcmdBackup,\t\t//备份\n\tcmdCompact,\t\t//合并？备份\n\tcmdCopy,\t\t//文件复制\n\tcmdFix,\t\t\t//重建索引\n\tcmdServer,\t\t//同时启动Master服务和Volume服务\n\tcmdMaster,\t\t//Master服务\n\tcmdFiler,\t\t//启动文件服务器，处理rest请求\n\tcmdUpload,\t\t//上传文件\n\tcmdDownload,\t//下载文件\n\tcmdShell,\t\t//开启交互命令行\n\tcmdVersion,\t\t//打印weedfs版本\n\tcmdVolume,\t\t//Volume服务\n\tcmdExport,\t\t//列出所有文件或者将数据导出\n\tcmdMount,\t\t//挂载filer到usespace，FUSE\n}\n```\n\n入口函数会使用range语法遍历Command里面的成员，不空则执行对应的命令\n\n## (请求)./weed/command/master.go\n\n如果执行的是master命令，那么这次命令将启动master服务。当执行master命令时，程序将从入口函数切换到master模块，执行该模块下的runMaster函数。这个函数最主要的功能是新建了一个mux实例。\n\n```go\n// 节选func run\tr := mux.NewRouter()\n\tms := weed_server.NewMasterServer(r,\n                                      *mport,\n                                      *metaFolder,\n                                      *volumeSizeLimitMB, \n                                      *volumePreallocate,\n                                      *mpulse,               \n                                   *defaultReplicaPlacement, \n                                      *garbageThreshold,\n                                      masterWhiteList, \n                                      *masterSecureKey,\n\t)Master(cmd *Command, args []string) bool\n\tr := mux.NewRouter()\n\tms := weed_server.NewMasterServer(r, *mport, \n                                      *metaFolder,\n                                      *volumeSizeLimitMB, \n                                      *volumePreallocate,\n                                      *mpulse, \n                                   *defaultReplicaPlacement, \n                                      *garbageThreshold,\n                                      masterWhiteList, \n                                      *masterSecureKey,\n\t)\n```\n\n\u003e golang自带的[http.SeverMux路由实现](http://studygolang.com/articles/4890)简单,本质是一个map[string]Handler,是请求路径与该路径对应的处理函数的映射关系。实现简单功能也比较单一\n\u003e 1. 不支持正则路由， 这个是比较致命的\n\u003e 2. 只支持路径匹配，不支持按照Method，header，host等信息匹配，所以也就没法实现RESTful架构\n\u003e\n\u003e 而gorilla/mux是一个强大的路由，小巧但是稳定高效，不仅可以支持正则路由还可以按照Method，header，host等信息匹配，可以从我们设定的路由表达式中提取出参数方便上层应用，而且完全兼容http.ServerMux\n\n具体的路由处理函数被放到了weed/server/master_server.go里面\n\n```go\n\tr.HandleFunc(\"/\", ms.uiStatusHandler)\n\tr.HandleFunc(\"/ui/index.html\", ms.uiStatusHandler)\n\tr.HandleFunc(\"/dir/assign\", ms.proxyToLeader(ms.guard.WhiteList(ms.dirAssignHandler)))\n\tr.HandleFunc(\"/dir/lookup\", ms.proxyToLeader(ms.guard.WhiteList(ms.dirLookupHandler)))\n\tr.HandleFunc(\"/dir/status\", ms.proxyToLeader(ms.guard.WhiteList(ms.dirStatusHandler)))\n\tr.HandleFunc(\"/col/delete\", ms.proxyToLeader(ms.guard.WhiteList(ms.collectionDeleteHandler)))\n\tr.HandleFunc(\"/vol/lookup\", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeLookupHandler)))\n\tr.HandleFunc(\"/vol/grow\", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeGrowHandler)))\n\tr.HandleFunc(\"/vol/status\", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeStatusHandler)))\n\tr.HandleFunc(\"/vol/vacuum\", ms.proxyToLeader(ms.guard.WhiteList(ms.volumeVacuumHandler)))\n\tr.HandleFunc(\"/submit\", ms.guard.WhiteList(ms.submitFromMasterServerHandler))\n\tr.HandleFunc(\"/delete\", ms.guard.WhiteList(ms.deleteFromMasterServerHandler))\n\tr.HandleFunc(\"/{fileId}\", ms.proxyToLeader(ms.redirectHandler))\n\tr.HandleFunc(\"/stats/counter\", ms.guard.WhiteList(statsCounterHandler))\n\tr.HandleFunc(\"/stats/memory\", ms.guard.WhiteList(statsMemoryHandler))\n```\n\n可以看到master部分负责的路由，对应的方法也是被二次封装了。被封装成\n\n```go\nfunc (ms *MasterServer) proxyToLeader(f func(w http.ResponseWriter, r *http.Request)) func(w http.ResponseWriter, r *http.Request)\n```\n\n不但如此，请求和响应也被封装到了一个函数里面。它的签名是\n\n```go\nfunc (g *Guard) WhiteList(f func(w http.ResponseWriter, r *http.Request)) func(w http.ResponseWriter, r *http.Request)\n```\n\n在这里weeedfs通过封装的方式将请求交给了安全模块/weed/guard。但目前这里似乎是一片空白。。。因为guard也是继续转发请求，但是这次是直接交到后台程序。\n\n至此，整个请求部分就完成了。\n\n(响应)","cover":"","link":"misc/2017/08/26/weedfs生命流程.html","preview":"\u003cp\u003eseaweedfs的生命流程\u0026hellip;\u003c/p\u003e\n","title":"weedfs生命流程"},{"content":"\n\n## 从测试看storlet的部署流程\n\nstorlet的测试入口`.unittest`如下：\n\n```shell\n#! /bin/bash\n\nSRC_DIR=$(python -c \"import os; print(os.path.dirname(os.path.realpath('$0')))\")\t#获取当前目录绝对地址\ncd ${SRC_DIR}/tests/unit\t#进入测试目录\nnosetests --exe -v $@\t#执行测试，返回结果\nrvalue=$?\t#返回上次的返回值\ncd -\t#返回上一次工作目录\n\nexit $rvalue\n```\n\nnosetest是一个python测试模块，它能够检测当前目录下所有的测试文件、方法并执行测试。然后我们的目的是为了理解storlet的运行流程，那么可以先找到一个一个用于测试某个storlet功能的用例，比如`tests/functional/java/test_compress_storlet.py`的部分代码如下:\n\n```python\nfrom swiftclient import client as c\nfrom tests.functional.java import StorletJavaFunctionalTest\nimport unittest\n\n\nclass TestCompressStorlet(StorletJavaFunctionalTest):\n    def setUp(self):\n        self.storlet_log = ''\n        self.additional_headers = {}\n        main_class = 'org.openstack.storlet.compress.CompressStorlet'\n        super(TestCompressStorlet, self).setUp('CompressStorlet',\n                                               'compressstorlet-1.0.jar',\n                                               main_class,\n                                               'input.txt')\n\n    def test_put(self):\n        headers = {'X-Run-Storlet': self.storlet_name}\n        headers.update(self.additional_headers)\n        querystring = \"action=compress\"\n\n        # simply set 1KB string data to compress\n        data = 'A' * 1024\n        \n··· ···\n```\n\n先去看一下它的父类`StorletJavaFunctionalTest`,它的代码如下：\n\n```python\nimport os\nfrom tests.functional import StorletFunctionalTest, PATH_TO_STORLETS\n\nBIN_DIR = 'bin'\n\n\nclass StorletJavaFunctionalTest(StorletFunctionalTest):\n    def setUp(self, storlet_dir, storlet_name, storlet_main,\n              storlet_file, dep_names=None, headers=None):\n        storlet_dir = os.path.join('java', storlet_dir)\n        path_to_bundle = os.path.join(PATH_TO_STORLETS, storlet_dir,\n                                      BIN_DIR)\n        super(StorletJavaFunctionalTest, self).setUp('Java',\n                                                     path_to_bundle,\n                                                     storlet_dir,\n                                                     storlet_name,\n                                                     storlet_main,\n                                                     storlet_file,\n                                                     dep_names,\n                                                     headers)\n```\n\n可以看到它的逻辑很简单，只是在语言选项那里换成了java，想必另外一个用python写的storlet也是类似。再看它的父类`StorletFunctionalTest`:\n\n```python\nimport unittest\nimport uuid\n\nfrom swiftclient import client as swiftclient\nfrom storlets.tools.cluster_config_parser import ClusterConfig\nfrom storlets.tools.utils import deploy_storlet, get_admin_auth, put_local_file\nimport os\n\nCONFIG_DIR = os.environ.get('CLUSTER_CONF_DIR', os.getcwd())\nCONFIG_FILE = os.path.join(CONFIG_DIR, 'cluster_config.json')\nPATH_TO_STORLETS = os.environ.get(\n    'STORLET_SAMPLE_PATH',\n    # assuming, current working dir is at top of storlet repo\n    os.path.join(os.getcwd(), 'StorletSamples'))\nCONSOLE_TIMEOUT = 2\n\n\nclass StorletBaseFunctionalTest(unittest.TestCase):\n    def setUp(self):\n        self.conf_file = CONFIG_FILE\n        try:\n            self.conf = ClusterConfig(CONFIG_FILE)\n        except IOError:\n            self.fail('cluster_config.json not found in %s. '\n                      'Please check your testing environment.' % CONFIG_DIR)\n\n        self.url, self.token = get_admin_auth(self.conf)\n        # TODO(kota_): do we need to call setUp() when inheriting TestCase\n        # directly? AFAIK, no setUp method in the class...\n        super(StorletBaseFunctionalTest, self).setUp()\n\n\nclass StorletFunctionalTest(StorletBaseFunctionalTest):\n\n    def create_container(self, container):\n        response = dict()\n        swiftclient.put_container(self.url, self.token,\n                                  container, headers=None,\n                                  response_dict=response)\n        status = response.get('status')\n        assert (status \u003e= 200 or status \u003c 300)\n\n    def cleanup_container(self, container):\n        # list all objects inside the container\n        _, objects = swiftclient.get_container(\n            self.url, self.token, container, full_listing=True)\n\n        # delete all objects inside the container\n        # N.B. this cleanup could run in parallel but currently we have a few\n        # objects in the user testing container so that, currently this does\n        # as sequential simply\n        for obj_dict in objects:\n            swiftclient.delete_object(\n                self.url, self.token, container, obj_dict['name'])\n        swiftclient.get_container(self.url, self.token, container)\n\n        # delete the container\n        swiftclient.delete_container(self.url, self.token, container)\n\n    def setUp(self, language, path_to_bundle,\n              storlet_dir,\n              storlet_name, storlet_main, storlet_file,\n              dep_names, headers):\n        super(StorletFunctionalTest, self).setUp()\n        self.storlet_dir = storlet_dir\n        self.storlet_name = storlet_name\n        self.storlet_main = storlet_main\n        self.dep_names = dep_names\n        self.path_to_bundle = path_to_bundle\n        self.container = 'container-%s' % uuid.uuid4()\n        self.storlet_file = storlet_file\n        self.headers = headers or {}\n        self.acct = self.url.split('/')[4]\n        self.deps = []\n        if dep_names:\n            for d in self.dep_names:\n                self.deps.append('%s/%s' % (self.path_to_bundle, d))\n        storlet = '%s/%s' % (self.path_to_bundle, self.storlet_name)\n\n        deploy_storlet(self.url, self.token,\n                       storlet, self.storlet_main,\n                       self.deps, language)\n\n        self.create_container(self.container)\n        if self.storlet_file:\n            put_local_file(self.url, self.token,\n                           self.container,\n                           self.path_to_bundle,\n                           self.storlet_file,\n                           self.headers)\n\n    def tearDown(self):\n        self.cleanup_container(self.container)\n\n```\n\n可以看到这个类是我们想找的类，它封装了storlet的部署流程。下面就来分析一下这个类。\n\n他首先定义了一些依赖，比如docker和编译好的storlet(在这里是jar,python那边有所不同)。先看一下docker的配置文件`cluster_config.json`。我的配置文件如下：\n\n```json\n{\n    \"groups\" : {\n        \"storlet-mgmt\": [\"127.0.0.1\"],\n        \"storlet-proxy\": [\"127.0.0.1\"],\n        \"storlet-storage\": [\"127.0.0.1\"],\n        \"docker\": [\"127.0.0.1\"]\n    },\n    \"all\" : {\n        \"ansible_ssh_user\" : \"daqu\",\n        \"docker_device\": \"/home/docker_device\",\n        \"storlet_source_dir\": \"~/storlets/\",\n        \"python_dist_packages_dir\": \"usr/local/lib/python2.7/dist-packages\",\n        \"storlet_gateway_conf_file\": \"/etc/swift/storlet_docker_gateway.conf\",\n        \"keystone_endpoint_host\": \"127.0.0.1\",\n        \"keystone_public_url\": \"http://127.0.0.1/identity/v3\",\n        \"keystone_admin_url\": \"http://127.0.0.1/identity_admin\",\n        \"keystone_admin_password\": \"admin\",\n        \"keystone_admin_user\": \"admin\",\n        \"keystone_admin_project\": \"admin\",\n        \"keystone_default_domain\": \"default\",\n        \"keystone_auth_version\": \"3\",\n        \"swift_endpoint_host\": \"127.0.0.1\",\n        \"swift_run_time_user\" : \"daqu\",\n        \"swift_run_time_group\" : \"daqu\",\n        \"swift_run_time_dir\": \"/opt/stack/data/swift/run\",\n        \"storlets_management_user\": \"daqu\",\n        \"storlet_management_account\": \"storlet_management\",\n        \"storlet_management_admin_username\": \"storlet_manager\",\n        \"storlet_manager_admin_password\": \"storlet_manager\",\n        \"storlet_management_swift_topology_container\": \"swift_cluster\",\n        \"storlet_management_swift_topology_object\": \"cluster_config.json\",\n        \"storlet_management_ansible_dir\": \"/opt/ibm/ansible/playbook\",\n        \"storlet_management_install_dir\": \"/opt/ibm\",\n        \"storlets_enabled_attribute_name\": \"storlet-enabled\",\n        \"docker_registry_random_string\": \"ABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJABCDEFGHIJ1234\",\n        \"docker_registry_port\": \"5001\",\n        \"container_install_dir\": \"/opt/storlets\",\n        \"storlets_default_project_name\": \"test\",\n        \"storlets_default_project_user_name\": \"tester\",\n        \"storlets_default_project_user_password\": \"testing\",\n        \"storlets_default_project_member_user\" : \"tester_member\",\n        \"storlets_default_project_member_password\" : \"member\",\n        \"base_image_maintainer\": \"root\",\n        \"base_os_image\": \"ubuntu_16.04\",\n        \"storlets_image_name_suffix\": \"ubuntu_16.04_jre8_storlets\",\n        \"swift_user_id\": \"1003\",\n        \"swift_group_id\": \"1003\",\n        \"storlet_middleware\": \"storlet_handler\",\n        \"storlet_container\": \"storlet\",\n        \"storlet_dependency\": \"dependency\",\n        \"storlet_log\": \"storletlog\",\n        \"storlet_images\": \"docker_images\",\n        \"storlet_timeout\": \"40\",\n        \"storlet_gateway_module\": \"docker\",\n        \"storlet_execute_on_proxy_only\": \"false\",\n        \"restart_linux_container_timeout\": \"3\"\n    }\n}\n```\n\n从上面可以看出，这个配置文件主要是设置docker中的storlet。\n\n然后便是编译好的storlet jar包。这个需要手动复制到`functional`目录下，否则测试会报错。\n\n接下来便是`StorletBaseFunctionalTest`，它先在读取docker配置文件，再通过get_admin_auth方法获取swift认证，事实上这个方法只是对swiftclient.get_auth方法进行了进一步的封装。然后这个类就结束了。它的功能很简单，读取配置和向swift发起认证请求。在这里值得一提的是get_admin_auth方法被定义在`storlets/tools/utils.py`中，这个模块还定义了如何上传一个storlet的过程。作者先是定义了一个将本地文件上传到swift的方法`put_local_file`，然后在定义一个方法`put_storlet_object`来调用前者上传storlet。在第二个方法中，作者指定了storlet上传的容器是storlet，并且在请求元数据中加入了和storlet相关的部分，比如：\n\n```html\n'X-Object-Meta-Storlet-Language': language,\n'X-Object-Meta-Storlet-Interface-Version': '1.0',\n'X-Object-Meta-Storlet-Object-Metadata': 'no',\n'X-Object-Meta-Storlet-Main': storlet_main_class\n```\n\n此外，还有一个方法`put_storlet_executable_dependencies`，它的作用和`put_storlet_object`类似，但是它上传的是依赖，上传的容器是dependency。\n\n当一个storlet和它的依赖都被上传时，这个storlet就算部署成功了。\n\n```python\ndef deploy_storlet(url, token, storlet, storlet_main_class, dependencies,\n                   language='Java'):\n    \"\"\"\n    Deploy storlet file and required dependencies as swift objects\n\n    :param url: swift endpoint url\n    :param token: token string to access swift\n    :param storlet: storlet file to be registerd\n    :param dependencies: a list of dependency files to be registered\n    :param language: storlet language. default value is Java\n    \"\"\"\n    # No need to create containers every time\n    # put_storlet_containers(url, token)\n    put_storlet_object(url, token, storlet,\n                       ','.join(os.path.basename(x) for x in dependencies),\n                       storlet_main_class, language)\n\n    put_storlet_executable_dependencies(url, token, dependencies)\n```\n\n\n\n然后是`StorletFunctionalTest(StorletBaseFunctionalTest)`，这个类其实是对刚才介绍的util模块的一次应用。在这个模块对这些方法又进行了封装。\n\n至此，整个storlet的溯源流程就结束了。总结一下：\n\n+ strolet的类结构从上到下为：\n  - unittest.TestCase\n  - StorletFunctionalTest\n  - StorletJavaFunctionalTest(StorletPythonFunctionalTest)\n  - TestCompressStorlet(实际的storlet)\n+ 每一层的类都是对storlet/util.py中操作的进一步封装\n+ storlet/util中定义部署storlet的方法\n\n","cover":"","link":"misc/2017/08/26/从测试看storlet的部署过程.html","preview":"\u003cp\u003e从测试的角度分析storlet是怎么运行的\u0026hellip;\u003c/p\u003e\n","title":"从测试看storlet的部署流程"},{"content":"\n\n## seaweedfs源码阅读(一)\n\n#### 1.随便看看\n\n作为一个新读者，一开始是很难把握项目的整个架构的。因此我先凭着感觉去看一下，然后便找到了`storage`目录。这个目录应该是讲怎么存储文件的，论文里面讲到needle代表着一个文件。那么先从`storage/needle.go`看起吧。\n\n```go\nconst (\n\tNeedleHeaderSize      = 16 //should never change this\n\tNeedlePaddingSize     = 8\n\tNeedleChecksumSize    = 4\n\tMaxPossibleVolumeSize = 4 * 1024 * 1024 * 1024 * 8\n\tTombstoneFileSize     = math.MaxUint32\n\tPairNamePrefix        = \"Seaweed-\"\n)\n```\n\n\n\n一开始就定义了一堆常量，不过从名字上比较好判断它们是干嘛的。但是目前只知道`MaxPossibleVolumeSize`应该意味着一个Volume最大是4G。然后接下来便是needle的定义。\n\n```go\ntype Needle struct {\n\tCookie uint32 `comment:\"random number to mitigate brute force lookups\"`\n\tId     uint64 `comment:\"needle id\"`\n\tSize   uint32 `comment:\"sum of DataSize,Data,NameSize,Name,MimeSize,Mime\"`\n\n\tDataSize     uint32 `comment:\"Data size\"` //version2\n\tData         []byte `comment:\"The actual file data\"`\n\tFlags        byte   `comment:\"boolean flags\"` //version2\n\tNameSize     uint8  //version2\n\tName         []byte `comment:\"maximum 256 characters\"` //version2\n\tMimeSize     uint8  //version2\n\tMime         []byte `comment:\"maximum 256 characters\"` //version2\n\tPairsSize    uint16 //version2\n\tPairs        []byte `comment:\"additional name value pairs, json format, maximum 64kB\"`\n\tLastModified uint64 //only store LastModifiedBytesLength bytes, which is 5 bytes to disk\n\tTtl          *TTL\n\n\tChecksum CRC    `comment:\"CRC32 to check integrity\"`\n\tPadding  []byte `comment:\"Aligned to 8 bytes\"`\n}\n```\n\n可以看到，一个needle携带蛮多信息。除了本身的数据比如Data、Id、cookie之外，它还携带了额外的信息比如Mime、Pairs、ttl(time to live?)等等。看来，一个needle是元数据和数据的结合。\n\n看到这里，发现什么都不懂。那么，seaweedfs源码的第一步就从storage模块开始吧。\n\n#### 2.storage\n\n##### needle.go\n\nstorage的目录结构如下：\n\n```powershell\n D:\\Temp\\seaweedfs-master\\weed\\storage 的目录\n\n2017/08/04  12:37    \u003cDIR\u003e          .\n2017/08/04  12:37    \u003cDIR\u003e          ..\n2017/07/28  23:33             4,682 compact_map.go\n2017/07/28  23:33               533 crc.go\n2017/07/28  23:33             4,432 disk_location.go\n2017/07/28  23:33             1,218 file_id.go\n2017/08/04  12:37    \u003cDIR\u003e          needle\n2017/07/28  23:33             6,641 needle.go\n2017/07/28  23:33               232 needle_byte_cache.go\n2017/07/28  23:33             3,090 needle_map.go\n2017/07/28  23:33             4,247 needle_map_boltdb.go\n2017/07/28  23:33             3,807 needle_map_leveldb.go\n2017/07/28  23:33             3,423 needle_map_memory.go\n2017/07/28  23:33             8,831 needle_read_write.go\n2017/07/28  23:33             1,182 needle_test.go\n2017/07/28  23:33             1,179 replica_placement.go\n2017/07/28  23:33               313 replica_placement_test.go\n2017/07/28  23:33             9,740 store.go\n2017/07/28  23:33             1,474 store_vacuum.go\n2017/07/28  23:33             3,041 volume.go\n2017/07/28  23:33             1,996 volume_checking.go\n2017/07/28  23:33               367 volume_create.go\n2017/07/28  23:33               438 volume_create_linux.go\n2017/07/28  23:33               356 volume_id.go\n2017/07/28  23:33             1,581 volume_info.go\n2017/07/28  23:33               303 volume_info_test.go\n2017/07/28  23:33             3,471 volume_loading.go\n2017/07/28  23:33             6,815 volume_read_write.go\n2017/07/28  23:33             2,267 volume_super_block.go\n2017/07/28  23:33               403 volume_super_block_test.go\n2017/07/28  23:33             7,093 volume_sync.go\n2017/07/28  23:33             2,394 volume_ttl.go\n2017/07/28  23:33             1,060 volume_ttl_test.go\n2017/07/28  23:33             9,432 volume_vacuum.go\n2017/07/28  23:33             1,713 volume_vacuum_test.go\n2017/07/28  23:33               132 volume_version.go\n```\n\n接着上面对`needle.go`的阅读。在needle的结构声明后是一个简单的String函数，它的功能就是把needle的字段打印出来。接着是一个巨长的`ParseUpload`的函数，虽然这个函数有点长，大概八十行这样子。但是它的功能还是挺简单的，他负责分析http请求。它接受一个http请求，然后返回一个包含大部分needle字段信息的元组，它的签名如下：\n\n```go\nfunc ParseUpload(r *http.Request) (\n\tfileName string, \n\tdata []byte, \n\tmimeType string, \n\tpairMap map[string]string, \n\tisGzipped bool,\n\tmodifiedTime uint64, \n\tttl *TTL, \n\tisChunkedFile bool, \n\te error)\n```\n\n在接受到一个请求后，它首先分析请求头。把所有Seaweed-前缀的字段提取出来。再读取数据，值得注意的是数据的传送协议是`multipart/form-data`。\n\n接下来是新建needle的函数，它的目的是将请求中的字段赋值给新的needle。这部分用到的结构体方法定义在`needle_read_write.go`。\n\n##### needle_read_write.go\n\n这部分定义了needle的一些关于读和写的方法。除了给needle结构体中赋值的方法外，剩下的方法都是关于needle如何操作io的。下面描述一下其中一个方法`Append`。\n\n```go\nfunc (n *Needle) Append(w io.Writer, version Version) (size uint32, actualSize int64, err error) {\n\tif s, ok := w.(io.Seeker); ok {\n\t\tif end, e := s.Seek(0, 1); e == nil {\n\t\t\tdefer func(s io.Seeker, off int64) {\n\t\t\t\tif err != nil {\n\t\t\t\t\tif _, e = s.Seek(off, 0); e != nil {\n\t\t\t\t\t\tglog.V(0).Infof(\"Failed to seek %s back to %d with error: %v\", w, off, e)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}(s, end)\n\t\t} else {\n\t\t\terr = fmt.Errorf(\"Cannot Read Current Volume Position: %v\", e)\n\t\t\treturn\n\t\t}\n\t}\n\t\n··· ···\n```\n\n首先，将Writer w通过类型断言转化Seeker。接着通过Seek方法从第0个字节开始读取数据，seek方法的两个参数分别代表偏移量和偏移起点，这里指的是从当前指针所在位置偏移0个字节。这里使用了设置匿名函数立即执行的方法，然后因为有defer修饰，所以是逆序立即执行。Seeker第二个参数有相应的常量\n\n\u003eSEEK_SET int = 0 //从文件的起始处开始设置 offset\n\u003eSEEK_CUR int = 1 //从文件的指针的当前位置处开始设置 offset\n\u003eSEEK_END int = 2 //从文件的末尾处开始设置 offset\n\n接下来就是数据写入的过程了。不过奇怪的是weedfs居然有两个版本。\n\n```go\n\tswitch version {\n\tcase Version1:\n\t\theader := make([]byte, NeedleHeaderSize)\n\t\tutil.Uint32toBytes(header[0:4], n.Cookie)\n\t\tutil.Uint64toBytes(header[4:12], n.Id)\n\t\tn.Size = uint32(len(n.Data))\n\t\tsize = n.Size\n\t\tutil.Uint32toBytes(header[12:16], n.Size)\n\t\tif _, err = w.Write(header); err != nil {\n\t\t\treturn\n\t\t}\n\t\tif _, err = w.Write(n.Data); err != nil {\n\t\t\treturn\n\t\t}\n\t\tactualSize = NeedleHeaderSize + int64(n.Size)\n\t\tpadding := NeedlePaddingSize - ((NeedleHeaderSize + n.Size + NeedleChecksumSize) % NeedlePaddingSize)\n\t\tutil.Uint32toBytes(header[0:NeedleChecksumSize], n.Checksum.Value())\n\t\t_, err = w.Write(header[0 : NeedleChecksumSize+padding])\n\t\treturn\n\tcase Version2:\n\t\theader := make([]byte, NeedleHeaderSize)\n\t\tutil.Uint32toBytes(header[0:4], n.Cookie)\n\t\tutil.Uint64toBytes(header[4:12], n.Id)\n\t\tn.DataSize, n.NameSize, n.MimeSize = uint32(len(n.Data)), uint8(len(n.Name)), uint8(len(n.Mime))\n\t\tif n.DataSize \u003e 0 {\n··· ···\n```\n\n就功能上来说，两个版本的作用都是一样的。因此在这里只分析第一个版本。它首先根据header大小(这里是16字节)分配了一块内存，然后逐个将needle的字段转为字节码。最后写进去，末尾会有校验验证，如果前面写失败的话会重试。\n\n剩下的就是跟读写操作相关的函数了。\n\n##### needle_map\n\n这部分由好几个文件构成，分别是基本数据结构`needle_map`和几个实例比如`needle_map_leveldb`等等。这部分主要是定义了NeedleMapper这个接口和baseNeedleMapper、mapMetric这两个结构。关于map的作用，目前我的理解还只是停留在论文的解释中。\n\n\u003e 每个Store机器管理多个物理卷。每个物理卷存有百万张图片。读者可以将一个物理卷想象为一个非常大的文件（100GB），保存为`/hay/haystack\u003clogical volume id\u003e`。Store机器仅需要逻辑卷ID和文件offset就能非常快的访问一个图片。这是Haystack设计的主旨：不需要磁盘操作就可以检索文件名、偏移量、文件大小等元数据。Store机器会将其下所有物理卷的文件描述符（open的文件“句柄”，卷的数量不多，数据量不大）缓存在内存中。同时，图片ID到文件系统元数据（文件、偏移量、大小等）的映射（后文简称为“内存中映射”）是检索图片的重要条件，也会全部缓存在内存中。为了快速的检索needle，Store机器需要为每个卷维护一个内存中的key-value映射。映射的Key就是（needle.key+needle.alternate_key）的组合，映射的Value就是needle的flag、size、卷offset（都以byte为单位）。如果Store机器崩溃、重启，它可以直接分析卷文件来重新构建这个映射（构建完成之前不处理请求）。\n\n由上可知，map的存在是为了让涉及到元数据的操作不经过磁盘操作，因此map的作用是为了把元数据存储到本地的数据库上。\n\n##### Volume\n\nVolume就是物理卷了，它的结构如下：\n\n```go\ntype Volume struct {\n\tId            VolumeId\n\tdir           string\n\tCollection    string\n\tdataFile      *os.File\n\tnm            NeedleMapper\n\tneedleMapKind NeedleMapType\n\treadOnly      bool\n\n\tSuperBlock\n\n\tdataFileAccessLock sync.Mutex\n\tlastModifiedTime   uint64 //unix time in seconds\n\n\tlastCompactIndexOffset uint64\n\tlastCompactRevision    uint16\n}\n```\n\n除了基本的信息外，每一个Volume都有一个NeedleMapper。这也证实了每一个卷负责维护该卷上文件的元数据。","cover":"","link":"misc/2017/08/26/seaweedfs源码阅读(一).html","preview":"\u003cp\u003eseaweedfs存储模块分析\u0026hellip;\u003c/p\u003e\n","title":"seaweedfs源码阅读(一)"},{"content":"\n\n\n# seaweedfs源码阅读(二)\n\n## 1.简要介绍\n\n如果是阅读一个成熟的项目，最好是先阅读早期的版本，因为阅读一个项目的重点在于理解其思想。比如Linux，Linux目前的版本(4.x)的代码规模已经达到几百万行，阅读这样一个庞然大物的难度是无法想象的。但是Linux 0.11版本的规模只有2万行，可谓是小巧玲珑，从这个版本出发可谓是省时省力。seaweedfs也是一样，因此这次来简单介绍一下seaweedfs早期版本`2011-12-13 08:17 53814`。\n\n## 2.要解决的任务\n\n可以简单的分为两类，一个是如何处理http请求，另外一个是如何将数据存储。具体点说，前者要是实现基于http的文件接口，包括查找、下载、上传。这里的难点在于如何处理文件的上传。后者的目的是为了将文件比如文本文件与逻辑结构Needle对应起来，并将其写入到Volume中。\n\n## 3.解决的思路\n\n网络请求通过golang的标准库中的路由组件进行处理，一个请求在被处理后调用存储模块相应的函数并进行相关的任务。\n\n## 4.怎么存储\n\n先从存储的最小单位Needle说起，在weedfs中needle是存储的“原子”。举个例子，要将一张已经上传的图片存储到weedfs中该怎么做呢？\n\n1. 拿到一张图片，这个条件已经满足了。\n2. 新建一个Needle。注意，这里的Needle还不是图片，它只是一群字段的集合，只是一段内存而已\n\n```go\n  Cookie uint8 \"用于唯一标识\"\n  Key uint64 \"文件ID\"\n  AlternateKey uint32 \"额外文件id\"\n  Size uint32 \"数据大小\"\n  Data []byte \"存储数据\"\n  Checksum int32 \"校验码\"\n  Padding []byte \"Aligned to 8 bytes\"\n```\n\n一个Needle是由Cookie+Key+AltKey三者组合并唯一标识的，Size和Data用于保存数据，在这里目前这两个字段为空，最后的Checksum和Padding用于校验\n\n3. 将Needle和图片对应起来。怎么对应，将图片写入到Needle.Data和补充完Needle.Size就可以了。注意这里写入的是图片对应的字节流。\n4. 现在已经有一个Needle，并且这个Needle也存储有对应的图片了。下一步该做什么呢？***注册***！每一个Needle都要向Needle_Map注册，只有这样才能找得到它们。因为每一个Needle都要被存储到一个大文件比如某个Volume服务器上的某个Volume中。在这里，Volume就代表一个大文件。当Needle存储在大文件中时，从物理实质看，每一个needle都是被顺序追加写入到大文件的末尾。那么，Needle_Map怎么找到它们呢？每一个Needle_Map维护着一个哈希表，它的键是Needle的key，它的值是一个叫做NeedleValue的数据结构，它的定义如下\n\n```go\ntype NeedleValue struct{\n  Offset uint32 \"Volume offset\" //since aligned to 8 bytes, range is 4G*8=32G\n  Size uint32 \"Size of the data portion\"\n}\n```\n\n该怎么理解这个结构呢？它其实是Needle在Volume上的存储标识。为什么这么说?因为要在Volume上找到一个Needle事实上只需要知道你在哪里开始存储的，你的大小是多少。知道这两点我就可以找到你。\n\n5. 现在，我们已经有了一个Needle和一个Needle_Map。那么下一步就是找一个Volume。如果没有Volume咋办，创建一个!那么一个Volume长啥样啊?\n\n```go\ntype Volume struct {\n\tId                  uint64\t//标识\n\tdir                 string\t//所在目录\n\tdataFile, indexFile *os.File\t//对应的大文件和索引文件\n\tnm                  *NeedleMap\t//needleMap\n\n\taccessChannel chan int\t//用于各Volume通信和master通信\n}\n```\n\n一个Volume起到的作用主要是存储和维护。存储needle和这个Volume的元数据信息。维护主要是和主节点保持通信\n\n6. 现在已经有Volume了，但是还是不能存储，为啥？因为找不到！因此我们还需要一个类似Needle_Map的东西也就是Volume_Map。对于每一个Volume来说，它只会记录它在哪个目录和有哪些needle。但是这对于找到它来说远远不够，是的我知道你这个Volume在哪个目录。但是是哪台电脑的目录啊？这个目录下可能有多个Volume，哪一个是你哇？这个问题就是由Volume_Map来解决的？它的结构如下\n\n```go\ntype Mapper struct {\n\tdir              string\t//map文件在哪个目录\n\tFileName         string\t//哪个是map文件\n\tId2Machine map[uint32][]*Machine\n\tLastId uint32\n}\n```\n\n在这个版本中，Volume_Map维护一个directorymap文件。这个文件告诉程序该如何找到它要找的Volume。\n\n7.现在Needle，Needle_Map，Volume，Volume_Map都有了，程序终于知道怎么找到一张图片\n\n```\n网络操作··· ···\n-\u003eVolume_Map（找Volume）\n-\u003eVolume（找Needle_Map）\n-\u003eNeedle_Map（根据key找到value，也就是needle在volume中的位置）\n-\u003e根据Needle_Map的信息从Volume中读取字节流\n-\u003e字节流转换\n-\u003e拿到Needle\n-\u003e读取Needle代表的文件\n```\n\n因此，程序可以放心地将图片存储到needle中。也就是执行Needle.write函数。\n\n至此，一个文件的存储工作就完成了。\n\n## 5.怎么发送文件请求\n\n前面介绍了文件是怎么存储的，但是就使用来说还有一个问题。就是我的使用请求怎么发出去啊？在这个版本中，weedfs的思路很简单，每一个文件请求都是HTTP请求。weedfs会将HTTP请求转换为相应模块的函数调用。\n\n## 6.总结\n\n这次解读了weedfs的早期版本，功能很简陋，但是核心功能已经实现了，网络到存储这部分的功能已经基本实现，但是用户到网络的部分只能说有个原型。","cover":"","link":"misc/2017/08/26/seaweedfs源码阅读(二).html","preview":"\u003cp\u003eseaweedfs早期版本分析\u0026hellip;\u003c/p\u003e\n","title":"seaweedfs源码阅读(二)"},{"content":"\n\n## openstack storlet简单介绍\n\n#### storlet的特点\n\nstorlet无法操作硬盘，网络甚至是swift的请求环境(可以理解为不能修改请求么？)\n\nstorlet在执行时不能被理解为一般意义上的工作进程，特别是那种需要大量临时内存的进程。因为它工作在一个沙盒环境中，不能使用太多内存。作者不建议用storlet创建临时文件。storlet的运行过程一般是从输入流读取数据，执行任务，然后将结果写入到输出流。\n\n值得注意的是，每一个storlet读取和存储的数据会根据调用方式的不同而发生改变：\n\n- **下载**--如果是在一个对象下载过程中调用storlet。那么用户接受到的输入流(inputstream)将是经过storlet转化(transform)过的。也就是说这时storlet接收到的数据不是存储在swift中的数据。\n- **上传** --如果是在一个对象上传过程中调用storlet。那么存储在swift中的数据将不会是它原来的数据，而是经过storlet转化的数据。\n- **操作(object copy)**--如果storlet要对一个对象进行持续操作，那么它的输出将会工作(keep in)在一个该对象的副本上。\n\n#### storlet是怎么被调用的\n\nstorlet的本质是swift的一个对象，存储在名叫storlet的容器中。但是storlet实现了一种底层机制(engine)使得这些storlet对象能够被动态的调用，storlet的生命流程可以简单地概括为拦截io请求-\u003e将请求重定向到storlet-\u003e返回storlet定制过的输出流。storlet的这种机制(engine)本质是swift的中间件。\n\n#### storlet是怎么部署的\n\nstorlet部署的过程可以分为三步，分别是编写storlet、编译打包storlet、将storlet作为一个对象上传到swift。再简单一点，可以说storlet的部署就是将打包好的storlet(包括依赖)上传到swift的特定的container中。\n\n#### storlet engine的本质\n\n前面提到，storlet engine其实是swift的中间件。每一个swift请求都会经过部署在swift上的中间件。那么一个请求在经过storlet engine时发生了什么事情呢？storlet engine在往下说，它其实是一个python WSGI，起到路由的作用。关于WSGI可以看这个[这个](http://www.nowamagic.net/academy/detail/1330310)","cover":"","link":"misc/2017/08/26/openstack storlet简单介绍.html","preview":"\u003cp\u003estorlet的特点、是怎么被调用的、是怎么部署的\u0026hellip;\u003c/p\u003e\n","title":"openstack storlet简单介绍"},{"content":"\n# SDS原型（二）\n\n## SDS VS 对象存储\n\n前面提到笔者的一个观点：凡是实现了restful接口的对象存储系统都可以看成是SDS的存储系统。那么，为什么要在对象存储上进行SDS的实践呢？如何实践？好处是什么？\n\n### 为什么\n\n在笔者看来，SDS代表一种架构，其目的是为了实现存储层次的控制和数据分离。前面说实现restful接口的对象存储可以看成是SDS系统，如果再详细一点可以说是提供restful接口的对象存储系统已经包含SDS的思想，但是从功能、架构上说还不是SDS架构。从功能上说，并没有给用户提供清晰的控制功能。从架构上看，目前对象存储的各模块基本都是基于功能的不同而划分的。\n\n举个例子，openstack swift的功能主要是关于文件的读取比如增删查改，关于文件控制的功能目前它只是提供了一个中间件机制来对请求进行过滤。如果把一个系统的各功能代码量所占总代码用百分比来描述这个功能所受重视程度的话，那么swift中控制部分的百分比是低于数据部分的。但是SDS提倡控制和数据分离，为什么要分离，因为要做更多的控制，为什么要做更多的控制，因为要提供更好的使用体验和更高的开发效率。也就是说，目前的对象存储或多或少地提供了控制层的功能，但是这距离SDS对控制的要求还有一定的距离。\n\n因此，笔者说要在对象存储上实践SDS的目的是增强对象存储的控制层的功能。\n\n### 目前已经有的SDS方案\n\n何谓实践?在it领域，就是将一套方案应用到某个业务场景中。那么，目前有哪些已经实现的SDS方案呢？(特指基于管理的SDS)\n\n1.IOflow \n\n早期的SDS原型，环境是windows。但是没有后续工作\n\n2.openstack swift\n\n\u003e  swift通过提供基于HTTP协议的API给外界调用来完成对象存储的功能，我们从swift的各个部署说明里面可以看到，proxy server和storage node的配置文件里面都有一个`[pipeline:main]`，这个是swift各个服务的请求链，由多个中间件组成的一个中间件集合。pipeline有点像J2EE里面filter，每个http请求需要经过各个服务的pipeline。\n\n一个pipeline实例如下\n\n```python\npipeline = catch_errors healthcheck proxy-logging bulk ratelimit crossdomain slo cache tempurl tempauth staticweb account-quotas container-quotas proxy-logging proxy-server\n```\n\n一个pipeline就是一群中间件的序列，可以看到。swift通过中间件可以来完成一些校验工作，比如catch_errors检查请求是否合法、完成记录工作比如proxy-logging。\n\n3.crystalSDS\n\ncrystal基于swift，它把swift当做数据层，它自己作为控制层。每一个向swift发出的文件请求都会被加入到swift pipeline的crystal的中间件拦截。等到控制层的crystal执行完之后再将请求发到下一个中间件。\n\n通过这种机制，crystal可以实现一些原本文件系统无法实现的功能，比如将文件先压缩再存储，先解压再读取。\n\n### SDS的好处\n\nSDS的好处是什么呢，提高了使用体验。举个例子，比如扫地，一个完整的步骤拿起扫把-\u003e逐个房间清扫-\u003e倒垃圾-\u003e放好工具。在这里，有一个叫做crystal的扫地机器人，如果使用crystal来扫地，那么整个过程就变成拿出crystal-\u003e按下扫地开关-\u003e关掉crystal-\u003e倒垃圾-\u003e放好crystal。\n\n对于用户来说，这极大地提升了扫地体验。因为原来需要一个个房间地走动，但是得益于crystal，现在这个步骤省去了。\n\n然而，就这个扫地的过程来说。整个过程其实变得复杂了，因为crystal在扫地的时候需要动态的判断障碍，动态改变路线。这个过程需要极大的计算量。\n\n看起来似乎这个举动没有好处啊，但是在这个场景中，用户体验是第一位的，毕竟是用户购买的产品。随着技术的发展，性能的提升越来越廉价。在性能与用户体验各占一边的天平上，随着市场的作用，天平是越来越倾向于用户体验这一边的。\n\nSDS也是如此，它提高了项目的规模，但却能带来更清晰易懂的架构和更好的用户体验。\n\n## 目前SDS方案的不足\n\n1.ioflow\n\n基于文件系统，实现控制层的开销过大\n\n2.swift\n\n控制功能不够丰富，不能支持更加复杂的操作，比如修改文件的存储格式、将文件进行拆分与合并。\n\n3.crystal\n\n与swift紧密耦合，每一个crystal实例是运行在沙盒环境中的，这是优点但也有局限性。比如使用crystal对多个文件进行合并，由于crystal实例之间的隔离性导致实例之间通信难度和开销较大。\n\n4.seaweedfs\n\n缺少控制层\n\n## 聚焦的问题\n\n笔者发现，在对象存储中。一个请求-响应的过程可以分为\n\n```\nstart\n# 网络\n客户端\n-\u003ehttp 文件请求\n-\u003e服务端 接收\n-\u003e路由转发\n# 存储\n-\u003e函数调用\n-\u003e读写\n-\u003e返回结果\n# 网络\n-\u003e服务端 发出响应\n-\u003e客户端收到响应\nend\n```\n\n在现有的SDS方案中，控制层没有覆盖到上面整个流程。crystal、swift的控制只能针对网络请求，但是当网络请求转化为文件io请求的时候无法进行控制。seaweedfs则相反，它将每一个文件都抽象为needle，对其能够进行合并操作。但是却没有请求拦截、重定向等功能。\n\n因此，笔者希望实现一个对象存储的控制层，它能够就对象存储的文件请求的整个生命流程进行控制。","cover":"","link":"misc/2017/08/26/sds原型(二).html","preview":"\u003cp\u003esds目前的方案以及存在的问题\u0026hellip;\u003c/p\u003e\n","title":"SDS原型（二）"},{"content":"\n完成的工作~\n\n1.输出SDS原型（二）\n\n2.mix与otp教程进行到第三","cover":"","link":"misc/2017/08/25/daqu-8-25.html","preview":"\u003cp\u003e写了一篇输出，研究了elixir的分布式存储的例子\u0026hellip;\u003c/p\u003e\n","title":"17-08-25  日报"},{"content":"\n\n完成的工作~\n\n1.输出SDS原型（一）\n\n2.输出weedfs源码阅读（二）","cover":"","link":"misc/2017/08/24/daqu-8-24.html","preview":"\u003cp\u003e写了两篇输出\u0026hellip;\u003c/p\u003e\n","title":"17-08-24  日报"},{"content":"\n完成的工作~\n\n1.根据weedfs早期版本修改了SDS原型的结构\n\n2.研究了weedfs第一个版本(2011-11-30 8fade...)的store部分代码，并且在修改它让其适应17年的go版本。原因是更容易理解和修改。\n\n在这个版本中小文件的存储是通过往块文件追加写的方式保存的，这个关系由数据结构NeedleValue维护，并且NeedleValue只存储偏移量和大小。还真是简单哈\n\n下一步工作~\n\n1.继续完成store部分的代码的修改\n\n2.争取明天让它跑起来","cover":"","link":"misc/2017/08/23/daqu-8-23.html","preview":"\u003cp\u003e找到weedfs早期版本，并简单地阅读了一下\u0026hellip;\u003c/p\u003e\n","title":"17-08-23  日报"},{"content":"\n完成的工作~\n\n1.为要实现的SDS原型设计了结构。\n\n2.简单的实现了文件的发送请求，就是发一个请求然后返回一个json\n\n下一步工作~\n\n1.继续完善","cover":"","link":"misc/2017/08/21/daqu-8-21.html","preview":"\u003cp\u003e还是在继续思考SDS原型，无聊地写了一些代码\u0026hellip;\u003c/p\u003e\n","title":"17-08-21  日报"},{"content":"\n完成的工作~\n\n1.研究了weedfs的源码结构，目的是思考如何将其变为sds结构。\n\n2.考虑如果要在weedfs上实现SDS的话，它的结构可以是\n\nFile-controller-data的形式？其中File代表元数据，用户在除文件下载的操作外都是和元数据打交道，controller负责转发文件请求，data代表实际的文件。\n\n3.简单实现了一个文件服务器\n\n下一步工作~\n\n1.继续思考\n\n2.找点时间研究一下如何实现一个SDS原型","cover":"","link":"misc/2017/08/18/daqu-8-18.html","preview":"\u003cp\u003e继续思考SDS原型，无聊地写了一些代码\u0026hellip;\u003c/p\u003e\n","title":"17-08-18  日报"},{"content":"\n完成的工作~\n\n1.测试了golang的任务序列Machinery，目的是将其作为存储节点的worker，结论是不适合。\n\n2.比较了swift和weedfs，发现这两者作为对象存储有相同的地方比如文件网关。\n\n- swift的文件网关是通过python的wsgi应用实现的。文件请求在到达存储前会有一个middleware机制来对其进行过滤从而实现\"文件网关\"的作用。\n- weedfs的文件网关是通过安全模块间接实现的。具体的过程是在文件服务器接受到请求后会先执行一个安全函数，用来检查访问IP是否在白名单内。\n\n3.重新审视了sds，目的是希望给控制和数据分离中的控制部分寻找一个定义。结果是认为openstack swift可以被说成是SDS，因为它通过中间件机制明确支持了控制。weedfs不能说是SDS，因为从控制和数据分离的观点来看它没有对两者做区分。\n\n4.weedfs代码阅读工作个人认为可以告一段落。\n\n下一步工作~\n\n1.暂无头绪","cover":"","link":"misc/2017/08/17/daqu-8-17.html","preview":"\u003cp\u003e阅读seaweedfs告一段落，开始思考SDS原型\u0026hellip;\u003c/p\u003e\n","title":"17-08-17  日报"},{"content":"\n完成的工作~\n\n1.weedfs对文件请求的处理是通过gorilla/mux来完成，从这个点出发找到了一些在请求-响应过程中用到的函数。\n\n2.尝试在上面的提到的函数中增加日志记录语句，但是终端并没有打印出来。因此去了解了一下weedfs用到的日志模块glog，但问题还没解决。\n\n3.思考如何进行控制和数据分离，回顾了一下sdn。不知道sdn的控制与转发分离是否对sds的控制和数据分离有所启示。\n\n下一步工作~\n\n1.继续阅读","cover":"","link":"misc/2017/08/16/daqu-8-16.html","preview":"\u003cp\u003e正在阅读seaweedfs，顺道回顾了SDN\u0026hellip;\u003c/p\u003e\n","title":"17-08-16 日报"},{"content":"\n\n完成的工作~\n\n1.阅读了weedfs command模块的部分代码\n\n2.就weedfs请求过程写了输出\n\n下一步工作~\n\n1.继续阅读","cover":"","link":"misc/2017/08/15/daqu-8-15.html","preview":"\u003cp\u003e正在阅读seaweedfs，command模块\u0026hellip;\u003c/p\u003e\n","title":"17-08-15 日报"},{"content":"\n完成的工作~\n\n- 继续阅读weedfs网络部分的代码\n\n- 在weedfs上实现软件定义存储的可能性\n\n  一个weedfs的文件请求从客户端发出到文件读取可以粗略地概括为\n\n  文件请求 --发出--\u003e Master Server --转发--\u003e Volume Server --查找--\u003e Volume --查找--\u003e 该Volume中的Super block(元数据) --读取--\u003e needle \n\n  为了在weedfs实现类似storlet的功能，第一步可以先思考如何weedfs满足storlet的依赖。\n\n  1.storlet通过一个swift mildleware实现请求拦截与转发，那么weedfs中存在类似的机制么？\n\n  \u003e 答案是否定的。\n\n  2.storlet的特点就是充分利用了存储节点的计算能力，但是这种前提是存储系统必须是分布式的，因为只有分布式，存储节点才能具备有独立的计算能力。\n\n  \u003e weedfs满足这个要求。\n\n  3.weedfs本身已经是针对小文件优化提出的解决方案，那么在weedfs上实现SDS的好处是什么？\n\n  \u003e weedfs专注于小文件存储问题，小文件的优化策略与文件系统是紧耦合的。SDS的目的在于控制和数据分离，SDS on weedfs不仅能够降低小文件优化与weedfs的耦合度，提高weedfs的通用性，而且用户能够将部分业务逻辑放在存储上实现，降低了上层系统的复杂度。\n\n  4.如何实现SDS on weedfs?\n\n  \u003e 参考swift，在Master Server、Volume Server中加入管道机制。每一个请求在进入server后将像水流过管道一样的遍历filter函数。在所有filter函数执行完之后继续其它工作。\n\n  5.假如已经有了SDS on weedfs，可以利用它做什么工作？\n\n  \u003e 将一些weedfs的功能通过策略的方式实现，比如weedfs允许在请求.jpg格式的文件加入长、宽两个参数，这样返回的jpg文件的格式就是设定好的长宽。然而，目前这个功能是以模块函数的形式实现的，这是没有的耦合度提升。总而言之，通过SDS可以进行降低weedfs复杂度的工作，将一些模块解耦。从而在不减少功能的情况下降低系统复杂度。\n\n下一步工作~\n\n- 继续阅读代码\n- 尝试边读边实现一个原型？","cover":"","link":"misc/2017/08/14/daqu-8-14.html","preview":"\u003cp\u003e正在阅读seaweedfs，网络部分进行中\u0026hellip;\u003c/p\u003e\n","title":"17-08-14 日报"},{"content":"\n完成的工作~\n\n1.开始阅读weedfs server部分源码，但遭遇困难。主要是无从下手。\n\n2.阅读一些网上的输出，希望根据前人的经验找到入手的方向\n\n- [分布式存储Seaweedfs源码分析](https://yanyiwu.com/work/2015/01/09/weed-fs-source-analysis.html)\n- [Weed-fs 源码解读](http://blog.csdn.net/baogang409/article/details/42105367)\n\n下一步工作~\n\n1.继续阅读代码","cover":"","link":"misc/2017/08/11/daqu-8-11.html","preview":"\u003cp\u003e正在阅读seaweedfs，进度缓慢\u0026hellip;\u003c/p\u003e\n","title":"17-08-11 日报"},{"content":"\n完成的工作~\n\n1. 简单的完成了weedfs storage部分代码的阅读(没有深入了解，有了一个基本认识)\n2. 对这部分工作作了记录\n\n下一步工作~\n\n1. 阅读weedfs处理文件请求部分的代码，思考它实现软件定义存储的可能性","cover":"","link":"misc/2017/08/10/daqu-8-10.html","preview":"\u003cp\u003e正在阅读seaweedfs\u0026hellip;\u003c/p\u003e\n","title":"17-08-10  日报"},{"content":"\n# 完成的工作~\n\n- 阅读seaweedfs的storage部分代码，但是只完成了两个文件的阅读。进度缓慢\n- 复习了[btree](http://blog.csdn.net/endlu/article/details/51720299)，因为seaweedfs用这个作为文件的数据结构。具体可见`storage/needle/btree_map.go`\n\n\n谷歌就btree写了一个golang 包，能够基于内存实现btree。然后seaweedfs用btree作为数据结构来维护文件。\n\n```go\nfunc NewBtreeMap() *BtreeMap {\n\treturn \u0026BtreeMap{\n\t\ttree: btree.New(32),\n\t}\n}\n\nfunc (cm *BtreeMap) Set(key Key, offset, size uint32) (oldOffset, oldSize uint32) {\n\tfound := cm.tree.ReplaceOrInsert(NeedleValue{key, offset, size})\n\tif found != nil {\n\t\told := found.(NeedleValue)\n\t\treturn old.Offset, old.Size\n\t}\n\treturn\n}\n\n··· ···\n```\n\n上面是weed中关于btree的部分，可以看到这部分负责创建btree的实例。然后weedfs将它与文件对应起来。在`needle_map.go`中\n\n```go\ntype NeedleMapper interface {\n\tPut(key uint64, offset uint32, size uint32) error\n\tGet(key uint64) (element *needle.NeedleValue, ok bool)\n\tDelete(key uint64, offset uint32) error\n\tClose()\n\tDestroy() error\n\tContentSize() uint64\n\tDeletedSize() uint64\n\tFileCount() int\n\tDeletedCount() int\n\tMaxFileKey() uint64\n\tIndexFileSize() uint64\n\tIndexFileContent() ([]byte, error)\n\tIndexFileName() string\n}\n```\n\n作者设置了NeedleMapper接口。因为前面btree模块中实现了这个接口中的Put、Get方法。这样Btree实例就可以通过这个接口和文件关联起来。\n\n\n- 复习了golang的一些语法，在阅读过程中复习的\n- 将weedfs在windows下的环境搭建作了总结\n\n## 待完成的工作~\n\n1. 继续阅读seaweedfs","cover":"","link":"misc/2017/08/09/daqu-8-9.html","preview":"\u003cp\u003e开始阅读seaweedfs\u0026hellip;\u003c/p\u003e\n","title":"17-08-09  日报"},{"content":"\n# 完成的工作~\n\n1. 了解了seaweedfs的基本使用，就一个文件的上传、下载等基本操作进行了实践\n2. 对seaweedfs写了输出\n\n## 待完成的工作~\n\n1. 阅读代码","cover":"","link":"misc/2017/08/08/daqu-8-8.html","preview":"\u003cp\u003e简单地操作了seaweedfs\u0026hellip;\u003c/p\u003e\n","title":"17-08-08  日报"},{"content":"\n# 完成的工作~\n\n1. 简单复习了haystack的论文\n\n2. - haystack的特点是足够简单（相比与其它方案）\n   - 合并是基于物理卷(逻辑概念是volume，是的物理概念和逻辑概念都是volume)合并，volume维护当前卷下的元数据\n   - needle可以被理解为精简过的inode?\n   - haystack是对象存储，不是文件系统。这点跟swift很像。文中似乎提到在不同场景下可以切换底层文件系统\n\n3. 阅读了seaweedfs的代码导读，理解了seaweedfs的代码结构\n\n4. - seaweedfs是haystack的开源实现\n   - seaweedfs可以简单分为集群模块和文件模块，集群模块的目的是为了维护分布式系统，文件模块的目的则是实现haystack。\n\n## 下一步工作~\n\n1. 深入阅读seaweedfs文件模块的代码\n2. 思考如何将haystack中的小文件优化封装成一个模块\n3. 思考如何在haystack中实现存储控制和数据的分离","cover":"","link":"misc/2017/08/07/daqu-8-7.html","preview":"\u003cp\u003e今天主要是阅读\u0026hellip;\u003c/p\u003e\n","title":"17-08-07  日报"},{"content":"\n\n# 完成的工作~\n  1.就storlet的部署过程写了输出\n\n## 待完成的工作~\n  1.根据测试编写一个storlet client来调用storlet","cover":"","link":"misc/2017/08/03/daqu-8-3.html","preview":"\u003cp\u003e就部署storlet写了输出\u0026hellip;\u003c/p\u003e\n","title":"17-08-03  日报"},{"content":"\r\n# 完成的工作~\r\n    1. 成功部署了s2aio，并输出打包好的虚拟机\r\n    2. 对storlet的生命流程写了输出\r\n    3. 运行单元测试，失败。修改后成功\r\n  \u003e 提示：缺少clusterjson\r\n\r\n  **此文件在另外一个目录下。移动过去，此错误解决。测试一个没通过**\r\n\r\n  \u003e 提示：jar包没找到\r\n\r\n  **这群jar包其实已经编译好。移动过去，有三个测试没通过**\r\n\r\n  \u003e 提示：缺少python 模块nbformat pexpect\r\n\r\n  **安装之后。还剩下一个测试没通过**\r\n\r\n  \u003e 提示：注意到该测试是为了测试ipython是否正确被整合到storlet\r\n\r\n  **此测试可有可无，因为storlet运行不需要ipython**\r\n\r\n  测试成功\r\n## 待完成的工作~\r\n    4. 部署storlet development\r\n\r\n","cover":"","link":"misc/2017/08/02/daqu-8-2.html","preview":"\u003cp\u003e成功部署storlet all in one环境\u0026hellip;\u003c/p\u003e\n","title":"17-08-02 日报"},{"content":"\r\n#完成的工作~\r\n    1. 解决了storlet部署过程中遇到的一些问题\r\n    - google json_simple-1.1.jar包缺乏 通过下载并放到依赖文件夹解决\r\n    - docker镜像构建中一个用于下载依赖的task执行失败 通过修改依赖地址解决\r\n      未完成的工作~\r\n    2. storlet的部署卡在docker任务[host_storlet_engine_install : Install C/Java codes on remote host]\r\n  一些观察到的现象~\r\n    3. storlet进程是运行在docker中的，但是在storlet的安装过程中我发现storlet是先安装在本机上？然后docker再把它包装成一个镜像。原因相同的依赖包google json_simple-1.1.jar要安装两次。\r\n##接下来的工作：\r\n    4. 继续完成storlet环境搭建工作\r\n    5. 阅读文档写输出\r\n","cover":"","link":"misc/2017/08/01/daqu-8-1.html","preview":"\u003cp\u003e还是在搭建storlet环境\u0026hellip;\u003c/p\u003e\n","title":"17-08-01 日报"},{"content":"\n\n# 完成的工作~\n\n研究storlet代码：\n\n    1. Scommon包是storlet的主要部分，阅读这个即可。推荐阅读的类。\n    - StorletOutStream.java 此类描述了storlet处理的文件流是什么样的\n    - StorletLogger.java 介绍了storlet的日志记录方式，通过这个类可以了解为什么println函数没有用的原因\n    - RangFileInputStream.java 介绍了storlet怎么处理流的，重要！！\n      以上代码都没有精读\n    2. Storlet的输入和输出都是通过stream来完成的，这不仅包括swift文件的传输，还包括log函数。\n  搭建storlet环境：\n    3. 网络是用的铁通，出口带宽太少。正在换成联通中。\n## 下一步的计划~\n    4. 速速搭好storlet all in one的环境并成功运行测试，并将其输出成虚拟机。然后传到小分队的群里\n    5. 在SAIO上检查storlet demo的代码。熟悉工作流程。","cover":"","link":"misc/2017/07/31/daqu-7-31.html","preview":"\u003cp\u003e搭建storlet环境\u0026hellip;\u003c/p\u003e\n","title":"17-07-31 日报"}]